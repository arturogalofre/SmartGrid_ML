{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. A brief overview of the project.**\n",
    "**2. Python code that splits the original Wisconsin breast cancer dataset into two subsets: training/validation (80%), and test (20%). Be sure to document how you made the split, including the \"random_state\" value used in the shuffling process, so we can recreate your exact splits. See \"model_selection.train_test_split\" for guidance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training/validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training/validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python code that uses an additional split to create a validation dataset or Python code that implements a cross-validation approach to tune the Random Forest model hyperparameters. Be sure to document how you created the validation data, including the \"random_state\" value used in the shuffling process, so we can recreate your exact splits. See \"model_selection.train_test_split\" or Scikit-Learn's User Guide Section 3 (Model selection and evaluation) for guidance.\n",
    "Procedure documenting your design process and the tradeoffs you considered in building a Random Forest Classifier.\n",
    "Python code that uses RandomForestClassifier to train, validate and test a Random Forest model. You may use any number of features from the dataset. Be sure to set the \"random_state\" so we can recreate your model.\n",
    "Inputs: A list of hyperparameters, and their new values, that were modified from their default values\n",
    "Outputs: The score value of the final model for each of the datasets: training, validation and test\n",
    "Observations: What could you do to improve the prediction score of your trained model on the validation data? How well does your final model predict the classes in the test data? Provide a list of all of the examples from the test data that are predicted incorrectly.\n",
    "The above process should be repeated with the Gradient Boosting learning algorithm. You should reuse the same splits by using the same random_state values. This way, your Gradient Boosting Classifier will see the same training, validation and test data. When you have completed the process with the Gradient Boosting Classifier, compare and contrast the results with those from the Random Forest Classifier. Do both algorithms make the same classification mistakes on the test data? Is one clearly better than the other? What advantages and disadvantages did you find for each of the two algorithms?\n",
    "Python code that splits the original Diabetes dataset into two subsets: training/validation (80%), and test (20%). Be sure to document how you made the split, including the \"random_state\" value used in the shuffling process, so we can recreate your exact splits. See \"model_selection.train_test_split\" for guidance.\n",
    "Python code that uses an additional split to create a validation dataset or Python code that implements a cross-validation approach to tune the Random Forest model hyperparameters. Be sure to document how you created the validation data, including the \"random_state\" value used in the shuffling process, so we can recreate your exact splits. See \"model_selection.train_test_split\" or Scikit-Learn's User Guide Section 3 (Model selection and evaluation) for guidance.\n",
    "Procedure documenting your design process and the tradeoffs you considered in building a Random Forest Regressor.\n",
    "Python code that uses RandomForestRegressor to train, validate and test a Random Forest model. You may use any number of features from the dataset. Be sure to set the \"random_state\" so we can recreate your model.\n",
    "Inputs: A list of hyperparameters, and their new values, that were modified from their default values\n",
    "Outputs: The score value of the final model for each of the datasets: training, validation and test\n",
    "Observations: What could you do to improve the prediction score of your trained model on the validation data? How well does your final model predict the targets in the test data? Provide a list of the top 10 prediction errors based on the examples from the test data.\n",
    "The above process should be repeated with the Gradient Boosting learning algorithm. You should reuse the same splits by using the same random_state values. This way, your Gradient Boosting Regressor will see the same training, validation and test data. When you have completed the process with the Gradient Boosting Regressor, compare and contrast the results with those from the Random Forest Regressor. Do both algorithms make similar errors on the same examples from the test data? Is one algorithm clearly better than the other? What advantages and disadvantages did you find for each of the two algorithms?\n",
    "A brief conclusion for the project."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
